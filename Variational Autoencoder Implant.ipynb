{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:25.227286Z",
     "start_time": "2020-10-29T08:28:24.457373Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Input, Flatten, Dense, Lambda, Reshape\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "#disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "#data_dir = pathlib.Path(\"C:/Users/Davran/0_Deep_Learning_Project/Implant Inspection/All_bok_div\")\n",
    "#data_dir_train = pathlib.Path(\"C:/Users/Davran/0_Deep_Learning_Project/Implant Inspection/DATASET_ORIGINAL/train/*/*\")\n",
    "#data_dir_test = pathlib.Path(\"C:/Users/Davran/0_Deep_Learning_Project/Implant Inspection/DATASET_ORIGINAL/test/*/*\")\n",
    "\n",
    "data_dir = pathlib.Path(\"C:/Users/Davran/0_Deep_Learning_Project/Implant Inspection\")\n",
    "data_dir_train = pathlib.Path(\"C:/Users/Davran/0_Deep_Learning_Project/Implant Inspection/All_bok_div/*/*\")\n",
    "data_dir_test = pathlib.Path(\"C:/Users/Davran/0_Deep_Learning_Project/Implant Inspection/All_bok_div/*/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.io.gfile.glob(str(data_dir_train))\n",
    "#filenames.extend(tf.io.gfile.glob(str(data_dir_test)))\n",
    "\n",
    "train_filenames, val_filenames = train_test_split(filenames, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isola images count in training set: 21\n",
      "Legacy images count in training set: 74\n",
      "Viper images count in training set: 111\n",
      "Reline images count in training set: 43\n",
      "M8M10 images count in training set: 30\n",
      "Xia images count in training set: 61\n"
     ]
    }
   ],
   "source": [
    "COUNT_ISOLA = len([filename for filename in train_filenames if \"Isola\" in filename])\n",
    "print(\"Isola images count in training set: \" + str(COUNT_ISOLA))\n",
    "\n",
    "COUNT_LEGACY = len([filename for filename in train_filenames if \"Legacy\" in filename])\n",
    "print(\"Legacy images count in training set: \" + str(COUNT_LEGACY))\n",
    "\n",
    "COUNT_VIPER = len([filename for filename in train_filenames if \"Viper\" in filename])\n",
    "print(\"Viper images count in training set: \" + str(COUNT_VIPER))\n",
    "\n",
    "COUNT_RELINE = len([filename for filename in train_filenames if \"Reline\" in filename])\n",
    "print(\"Reline images count in training set: \" + str(COUNT_RELINE))\n",
    "\n",
    "COUNT_M8M10 = len([filename for filename in train_filenames if \"M8M10\" in filename])\n",
    "print(\"M8M10 images count in training set: \" + str(COUNT_M8M10))\n",
    "\n",
    "COUNT_XIA = len([filename for filename in train_filenames if \"Xia\" in filename])\n",
    "print(\"Xia images count in training set: \" + str(COUNT_XIA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\n",
    "val_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)\n",
    "\n",
    "for f in train_list_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\n",
    "print(\"Training images count: \" + str(TRAIN_IMG_COUNT))\n",
    "\n",
    "VAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\n",
    "print(\"Validating images count: \" + str(VAL_IMG_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = np.array([str(tf.strings.split(item, os.path.sep)[-1].numpy())[2:-1]\n",
    "                        for item in tf.io.gfile.glob(str(data_dir) + \"/All_bok_div/*\")])\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'Isola':\n",
    "        return 1\n",
    "    elif parts[-2] == 'Viper':\n",
    "        return 2\n",
    "    elif parts[-2] == 'M8M10':\n",
    "        return 3\n",
    "    elif parts[-2] == 'Reline':\n",
    "        return 4\n",
    "    elif parts[-2] == 'Legacy':\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # convert the compressed string\n",
    "  img_X = tf.image.decode_jpeg(img, channels=1)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img_X = tf.image.convert_image_dtype(img_X, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img_X, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "IMAGE_SIZE = [28, 28]\n",
    "train_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "val_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for image, label in train_ds:\n",
    "    X_train.append(image)\n",
    "    y_train.append(label)    \n",
    "X_train = np.array(X_train, 'float32')\n",
    "y_train = np.array(y_train, 'float32')\n",
    "\n",
    "#trainX = X_train.copy()\n",
    "#trainy = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in val_ds:\n",
    "    X_test.append(image)\n",
    "    y_test.append(label)\n",
    "X_test = np.array(X_test, 'float32')\n",
    "y_test = np.array(y_test, 'float32')\n",
    "\n",
    "#testX = X_test.copy()\n",
    "#testy = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:27.591922Z",
     "start_time": "2020-10-29T08:28:27.514583Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "input_data = tensorflow.keras.layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "encoder = tensorflow.keras.layers.Conv2D(64, (3,3), activation='relu')(input_data)\n",
    "#encoder = tensorflow.keras.layers.MaxPooling2D((2,2))(encoder)\n",
    "\n",
    "encoder = tensorflow.keras.layers.Conv2D(64, (3,3), activation='relu')(encoder)\n",
    "#encoder = tensorflow.keras.layers.MaxPooling2D((2,2))(encoder)\n",
    "\n",
    "encoder = tensorflow.keras.layers.Conv2D(32, (3,3), activation='relu')(encoder)\n",
    "#encoder = tensorflow.keras.layers.MaxPooling2D((2,2))(encoder)\n",
    "\n",
    "encoder = tensorflow.keras.layers.Flatten()(encoder)\n",
    "encoder = tensorflow.keras.layers.Dense(32)(encoder)\n",
    "encoder = tensorflow.keras.layers.Dense(32)(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Distribution and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:27.597584Z",
     "start_time": "2020-10-29T08:28:27.593455Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_latent_features(distribution):\n",
    "    distribution_mean, distribution_variance = distribution\n",
    "    batch_size = tensorflow.shape(distribution_variance)[0]\n",
    "    random = tensorflow.keras.backend.random_normal(shape=(batch_size, tensorflow.shape(distribution_variance)[1]))\n",
    "    return distribution_mean + tensorflow.exp(0.5 * distribution_variance) * random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:27.642131Z",
     "start_time": "2020-10-29T08:28:27.599269Z"
    }
   },
   "outputs": [],
   "source": [
    "distribution_mean = tensorflow.keras.layers.Dense(64, name='mean')(encoder)\n",
    "distribution_variance = tensorflow.keras.layers.Dense(64, name='log_variance')(encoder)\n",
    "latent_encoding = tensorflow.keras.layers.Lambda(sample_latent_features)([distribution_mean, distribution_variance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## without hyperparameters\n",
    "\n",
    "encoder_model = tensorflow.keras.Model(input_data, latent_encoding)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:27.657199Z",
     "start_time": "2020-10-29T08:28:27.643595Z"
    }
   },
   "outputs": [],
   "source": [
    "#encoder_model = tensorflow.keras.Model(input_data, latent_encoding)\n",
    "#encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:27.770230Z",
     "start_time": "2020-10-29T08:28:27.658973Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_input = tensorflow.keras.layers.Input(shape=(64))\n",
    "decoder = tensorflow.keras.layers.Dense(21*21*32)(decoder_input)\n",
    "decoder = tensorflow.keras.layers.Reshape((21, 21, 32))(decoder)\n",
    "decoder = tensorflow.keras.layers.Conv2DTranspose(32, (3,3), activation='relu')(decoder)\n",
    "decoder = tensorflow.keras.layers.UpSampling2D((2,2))(decoder)\n",
    "\n",
    "decoder = tensorflow.keras.layers.Conv2DTranspose(32, (3,3), activation='relu')(decoder)\n",
    "decoder = tensorflow.keras.layers.UpSampling2D((2,2))(decoder)\n",
    "\n",
    "decoder = tensorflow.keras.layers.Conv2DTranspose(64, (3,3), activation='relu')(decoder)\n",
    "#decoder = tensorflow.keras.layers.UpSampling2D((2,2))(decoder)\n",
    "\n",
    "decoder_output = tensorflow.keras.layers.Conv2DTranspose(1, (3,3), activation='relu')(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:27.780926Z",
     "start_time": "2020-10-29T08:28:27.771600Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_model = tensorflow.keras.Model(decoder_input, decoder_output)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:27.852821Z",
     "start_time": "2020-10-29T08:28:27.782557Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded = encoder_model(input_data)\n",
    "decoded = decoder_model(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:27.859119Z",
     "start_time": "2020-10-29T08:28:27.854102Z"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder = tensorflow.keras.models.Model(input_data, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function (Reconstruction Loss + KL-loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:27.869241Z",
     "start_time": "2020-10-29T08:28:27.860915Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss(distribution_mean, distribution_variance):\n",
    "    \n",
    "    def get_reconstruction_loss(y_true, y_pred):\n",
    "        reconstruction_loss = tensorflow.keras.losses.mse(y_true, y_pred)\n",
    "        reconstruction_loss_batch = tensorflow.reduce_mean(reconstruction_loss)\n",
    "        return reconstruction_loss_batch\n",
    "    \n",
    "    def get_kl_loss(distribution_mean, distribution_variance):\n",
    "        kl_loss = 1 + distribution_variance - tensorflow.square(distribution_mean) - tensorflow.exp(distribution_variance)\n",
    "        kl_loss_batch = tensorflow.reduce_mean(kl_loss)\n",
    "        return kl_loss_batch*(-0.5)\n",
    "    \n",
    "    def total_loss(y_true, y_pred):\n",
    "        reconstruction_loss_batch = get_reconstruction_loss(y_true, y_pred)\n",
    "        kl_loss_batch = get_kl_loss(distribution_mean, distribution_variance)\n",
    "        return reconstruction_loss_batch + kl_loss_batch\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:27.997052Z",
     "start_time": "2020-10-29T08:28:27.870567Z"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(loss=get_loss(distribution_mean, distribution_variance), optimizer='adam')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:57:07.457731Z",
     "start_time": "2020-10-29T08:28:28.436207Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train, X_train, epochs=100, batch_size=16, validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T09:04:57.028823Z",
     "start_time": "2020-10-29T09:04:55.826816Z"
    }
   },
   "outputs": [],
   "source": [
    "offset=20\n",
    "print (\"Real Test Images\")\n",
    "# Real Images\n",
    "plt.figure(figsize = (10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(X_test[i+offset,:,:, -1], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructed Images\n",
    "print (\"Reconstructed Images with Variational Autoencoder\")\n",
    "plt.figure(figsize = (10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    output = autoencoder.predict(np.array([X_test[i+offset]]))\n",
    "    op_image = np.reshape(output[0]*255, (100, 100))\n",
    "    plt.imshow(op_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent feature clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T09:05:21.259173Z",
     "start_time": "2020-10-29T09:05:10.611818Z"
    }
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "for i in range(500):\n",
    "    z.append(testy[i])\n",
    "    op = encoder_model.predict(np.array([X_test[i]]))\n",
    "    x.append(op[0][0])\n",
    "    y.append(op[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T09:05:22.024825Z",
     "start_time": "2020-10-29T09:05:21.260209Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['x'] = x\n",
    "df['y'] = y\n",
    "df['z'] = [\"digit-\"+str(k) for k in z]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='x', y='y', hue='z', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T09:05:37.654984Z",
     "start_time": "2020-10-29T09:05:37.652454Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_model = decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T09:05:59.751180Z",
     "start_time": "2020-10-29T09:05:59.748348Z"
    }
   },
   "outputs": [],
   "source": [
    "x_values = np.linspace(-3, 3, 30)\n",
    "y_values = np.linspace(-3, 3, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T10:22:57.086833Z",
     "start_time": "2020-10-29T10:22:55.079429Z"
    }
   },
   "outputs": [],
   "source": [
    "figure = np.zeros((28 * 30, 28 * 30))\n",
    "for ix, x in enumerate(x_values):\n",
    "    for iy, y in enumerate(y_values):\n",
    "        latent_point = np.array([[x, y]])\n",
    "        generated_image = generator_model.predict(latent_point)[0]\n",
    "        figure[ix*28:(ix+1)*28, iy*28:(iy+1)*28,] = generated_image[:,:,-1]\n",
    " \n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(figure, cmap='gray', extent=[3,-3,3,-3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
